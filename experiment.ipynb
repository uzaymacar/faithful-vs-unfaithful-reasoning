{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, TypedDict\n",
    "from utils import Question, QsDataset\n",
    "from functools import partial\n",
    "import plotly.express as px\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 642 faithful and 179 unfaithful CoTs out of 1238 total CoTs.\n"
     ]
    }
   ],
   "source": [
    "with open('results/deepseek_r1_cots_iphr_eval.json', 'r') as f:\n",
    "    cots = json.load(f)\n",
    "\n",
    "# NOTE: I'm not sure about the below way of getting faithful CoTs\n",
    "# cots_faithful = [x for x in cots if x['is_faithful_iphr'] == True]\n",
    "cots_faithful = [x for x in cots if x['is_faithful_iphr'] == True or (x['is_faithful_iphr'] == None and x['eval_final_answer'] == x['ground_truth_answer'])]\n",
    "cots_unfaithful = [x for x in cots if x['is_faithful_iphr'] == False]\n",
    "print(f\"Found {len(cots_faithful)} faithful and {len(cots_unfaithful)} unfaithful CoTs out of {len(cots)} total CoTs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wm-book-length',\n",
       " 'boiling-points',\n",
       " 'celebrity-heights',\n",
       " 'wm-nyt-pubdate',\n",
       " 'element-numbers',\n",
       " 'wm-us-city-long',\n",
       " 'wm-person-age',\n",
       " 'first-flights',\n",
       " 'melting-points',\n",
       " 'wm-person-death',\n",
       " 'river-lengths',\n",
       " 'wm-nyc-place-long',\n",
       " 'sound-speeds',\n",
       " 'wm-movie-length',\n",
       " 'wm-song-release',\n",
       " 'tech-releases',\n",
       " 'wm-nyc-place-lat',\n",
       " 'wm-us-city-lat',\n",
       " 'tunnel-lengths',\n",
       " 'wm-person-birth',\n",
       " 'wm-movie-release',\n",
       " 'animals-speed',\n",
       " 'bridge-lengths',\n",
       " 'wm-book-release',\n",
       " 'skyscraper-heights',\n",
       " 'structure-completion',\n",
       " 'aircraft-speeds',\n",
       " 'mountain-heights',\n",
       " 'wm-us-city-dens',\n",
       " 'element-densities',\n",
       " 'sea-depths',\n",
       " 'train-speeds',\n",
       " 'satellite-launches']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open('results/deepseek_r1_cots_iphr.json', 'r') as f:\n",
    "    cots_raw = json.load(f)\n",
    "\n",
    "list(set([x['prop_id'] for x in cots_raw]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Model loaded: DeepSeek-R1-Distill-Qwen-1.5B\n",
      "  Context length: 2048\n",
      "  Layers: 28\n",
      "  Vocab size: 151936\n",
      "  Hidden dim: 1536\n",
      "  Attention heads: 12\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "# NOTE: Ensure the model name is added to OFFICIAL_MODEL_NAMES in TransformerLens loading_from_pretrained.py. Also consider adjusting n_ctx if needed.\n",
    "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
    "context_length = 2048\n",
    "batch_size = 4  # Number of questions to process per batch\n",
    "temperature = 0.6  # Sampling temperature\n",
    "max_new_tokens = 1024  # Maximum number of new tokens to generate\n",
    "top_p = 0.92  # Nucleus sampling top-p value\n",
    "    \n",
    "# Disable gradient computation for faster inference\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Model loading\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model = HookedTransformer.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "model.cfg.n_ctx = context_length # Adjust context length if necessary\n",
    "print(f\"Model loaded: {model.cfg.model_name}\")\n",
    "print(f\"  Context length: {model.cfg.n_ctx}\")\n",
    "print(f\"  Layers: {model.cfg.n_layers}\")\n",
    "print(f\"  Vocab size: {model.cfg.d_vocab}\")\n",
    "print(f\"  Hidden dim: {model.cfg.d_model}\")\n",
    "print(f\"  Attention heads: {model.cfg.n_heads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_unfaithful = cots_unfaithful[0]\n",
    "logits, cache = model.run_with_cache(example_unfaithful['generated_cot'], remove_batch_dim=True)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CoTs loaded: 1239\n",
      "Faithful CoTs: 642\n",
      "Unfaithful CoTs: 180\n",
      "\n",
      "Property distribution in dataset:\n",
      "  wm-book-length: 300\n",
      "  element-numbers: 84\n",
      "  aircraft-speeds: 57\n",
      "  boiling-points: 56\n",
      "  bridge-lengths: 56\n",
      "  element-densities: 56\n",
      "  first-flights: 56\n",
      "  satellite-launches: 56\n",
      "  sea-depths: 56\n",
      "  skyscraper-heights: 56\n",
      "  tech-releases: 56\n",
      "  animals-speed: 52\n",
      "  celebrity-heights: 44\n",
      "  sound-speeds: 43\n",
      "  train-speeds: 42\n",
      "  tunnel-lengths: 42\n",
      "  mountain-heights: 36\n",
      "  river-lengths: 36\n",
      "  melting-points: 28\n",
      "  structure-completion: 27\n",
      "\n",
      "Found 0 reversed question pairs\n",
      "\n",
      "Found 0 questions with both faithful and unfaithful CoTs\n",
      "\n",
      "Found 0 additional pairs where reversed questions have faithful/unfaithful CoTs\n",
      "\n",
      "Total paired examples for analysis: 0\n",
      "\n",
      "Property distribution in paired examples:\n"
     ]
    }
   ],
   "source": [
    "# First, let's examine our data\n",
    "print(f\"Total CoTs loaded: {len(cots)}\")\n",
    "print(f\"Faithful CoTs: {len(cots_faithful)}\")\n",
    "print(f\"Unfaithful CoTs: {len(cots_unfaithful)}\")\n",
    "\n",
    "# Let's look at the properties represented in our dataset\n",
    "prop_counts = defaultdict(int)\n",
    "for cot in cots:\n",
    "    prop_counts[cot.get('prop_id', 'unknown')] += 1\n",
    "\n",
    "print(\"\\nProperty distribution in dataset:\")\n",
    "for prop, count in sorted(prop_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {prop}: {count}\")\n",
    "\n",
    "# Following the pairing logic from step2_evaluate_cots.py\n",
    "# First, create a mapping from reversed question IDs to original question IDs\n",
    "reversed_qid_map = {}\n",
    "\n",
    "for cot in cots:\n",
    "    qid = cot['qid']\n",
    "    prop_id = cot['prop_id']\n",
    "    comparison = cot['comparison']\n",
    "    question_text = cot['question_text']\n",
    "    \n",
    "    # Create a reversed question ID by flipping the comparison\n",
    "    reversed_comparison = 'lt' if comparison == 'gt' else 'gt'\n",
    "    \n",
    "    # Find the reversed question in the dataset\n",
    "    for other_cot in cots:\n",
    "        if (other_cot['prop_id'] == prop_id and \n",
    "            other_cot['comparison'] == reversed_comparison and\n",
    "            other_cot['qid'] != qid):\n",
    "            \n",
    "            # Check if this is a reversed pair (same entities but reversed comparison)\n",
    "            # This is a simplified check - the actual logic might need to be more sophisticated\n",
    "            if set(question_text.lower().split()) == set(other_cot['question_text'].lower().split()):\n",
    "                reversed_qid_map[qid] = other_cot['qid']\n",
    "                reversed_qid_map[other_cot['qid']] = qid\n",
    "                break\n",
    "\n",
    "print(f\"\\nFound {len(reversed_qid_map) // 2} reversed question pairs\")\n",
    "\n",
    "# Now organize CoTs by question ID\n",
    "question_pairs = defaultdict(dict)\n",
    "for cot in cots:\n",
    "    qid = cot['qid']\n",
    "    is_faithful = cot.get('is_faithful_iphr')\n",
    "    \n",
    "    # Only include examples where faithfulness is explicitly marked\n",
    "    if is_faithful is not None:\n",
    "        if is_faithful:\n",
    "            question_pairs[qid]['faithful'] = cot\n",
    "        else:\n",
    "            question_pairs[qid]['unfaithful'] = cot\n",
    "\n",
    "# Find questions that have both faithful and unfaithful examples\n",
    "paired_questions = {qid: pair for qid, pair in question_pairs.items() \n",
    "                   if 'faithful' in pair and 'unfaithful' in pair}\n",
    "\n",
    "print(f\"\\nFound {len(paired_questions)} questions with both faithful and unfaithful CoTs\")\n",
    "\n",
    "# Let's also find reversed pairs where one has faithful and the other has unfaithful\n",
    "reversed_faithful_unfaithful_pairs = []\n",
    "\n",
    "for qid, pair in question_pairs.items():\n",
    "    # Skip if this question already has both faithful and unfaithful\n",
    "    if 'faithful' in pair and 'unfaithful' in pair:\n",
    "        continue\n",
    "    \n",
    "    # Check if there's a reversed question\n",
    "    reversed_qid = reversed_qid_map.get(qid)\n",
    "    if reversed_qid and reversed_qid in question_pairs:\n",
    "        reversed_pair = question_pairs[reversed_qid]\n",
    "        \n",
    "        # Check if we can form a faithful/unfaithful pair across the two questions\n",
    "        if 'faithful' in pair and 'unfaithful' in reversed_pair:\n",
    "            reversed_faithful_unfaithful_pairs.append((qid, reversed_qid))\n",
    "        elif 'unfaithful' in pair and 'faithful' in reversed_pair:\n",
    "            reversed_faithful_unfaithful_pairs.append((reversed_qid, qid))\n",
    "\n",
    "print(f\"\\nFound {len(reversed_faithful_unfaithful_pairs)} additional pairs where reversed questions have faithful/unfaithful CoTs\")\n",
    "\n",
    "# Let's examine one example pair\n",
    "if paired_questions:\n",
    "    example_pair = next(iter(paired_questions.values()))\n",
    "    print(\"\\nExample question with both faithful and unfaithful CoTs:\")\n",
    "    print(f\"Question: {example_pair['faithful']['question_text']}\")\n",
    "    print(f\"Ground truth answer: {example_pair['faithful']['ground_truth_answer']}\")\n",
    "    print(f\"Property ID: {example_pair['faithful']['prop_id']}\")\n",
    "    \n",
    "    print(\"\\nFaithful reasoning:\")\n",
    "    faithful_cot = example_pair['faithful']['generated_cot']\n",
    "    # Print just the first few lines to avoid overwhelming output\n",
    "    print('\\n'.join(faithful_cot.split('\\n')[:10]) + '\\n...')\n",
    "    \n",
    "    print(\"\\nUnfaithful reasoning:\")\n",
    "    unfaithful_cot = example_pair['unfaithful']['generated_cot']\n",
    "    print('\\n'.join(unfaithful_cot.split('\\n')[:10]) + '\\n...')\n",
    "\n",
    "# Let's also examine a reversed pair example\n",
    "if reversed_faithful_unfaithful_pairs:\n",
    "    faithful_qid, unfaithful_qid = reversed_faithful_unfaithful_pairs[0]\n",
    "    faithful_cot = question_pairs[faithful_qid]['faithful']\n",
    "    unfaithful_cot = question_pairs[unfaithful_qid]['unfaithful']\n",
    "    \n",
    "    print(\"\\nExample of reversed questions with faithful/unfaithful CoTs:\")\n",
    "    print(f\"Faithful question: {faithful_cot['question_text']}\")\n",
    "    print(f\"Faithful ground truth: {faithful_cot['ground_truth_answer']}\")\n",
    "    \n",
    "    print(f\"\\nUnfaithful question: {unfaithful_cot['question_text']}\")\n",
    "    print(f\"Unfaithful ground truth: {unfaithful_cot['ground_truth_answer']}\")\n",
    "    \n",
    "    print(\"\\nFaithful reasoning:\")\n",
    "    print('\\n'.join(faithful_cot['generated_cot'].split('\\n')[:10]) + '\\n...')\n",
    "    \n",
    "    print(\"\\nUnfaithful reasoning:\")\n",
    "    print('\\n'.join(unfaithful_cot['generated_cot'].split('\\n')[:10]) + '\\n...')\n",
    "\n",
    "# Create a combined dataset of all paired examples for analysis\n",
    "all_paired_examples = []\n",
    "\n",
    "# Add direct pairs\n",
    "for qid, pair in paired_questions.items():\n",
    "    all_paired_examples.append({\n",
    "        'faithful': pair['faithful'],\n",
    "        'unfaithful': pair['unfaithful'],\n",
    "        'pair_type': 'direct'\n",
    "    })\n",
    "\n",
    "# Add reversed pairs\n",
    "for faithful_qid, unfaithful_qid in reversed_faithful_unfaithful_pairs:\n",
    "    all_paired_examples.append({\n",
    "        'faithful': question_pairs[faithful_qid]['faithful'],\n",
    "        'unfaithful': question_pairs[unfaithful_qid]['unfaithful'],\n",
    "        'pair_type': 'reversed'\n",
    "    })\n",
    "\n",
    "print(f\"\\nTotal paired examples for analysis: {len(all_paired_examples)}\")\n",
    "\n",
    "# Let's also analyze the distribution of properties in our paired examples\n",
    "paired_props = defaultdict(int)\n",
    "for pair in all_paired_examples:\n",
    "    paired_props[pair['faithful']['prop_id']] += 1\n",
    "\n",
    "print(\"\\nProperty distribution in paired examples:\")\n",
    "for prop, count in sorted(paired_props.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {prop}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_residual_component(corrupted_residual_component, hook, pos, clean_cache):\n",
    "    \"\"\"Patch a specific position in the residual stream with values from the clean cache.\"\"\"\n",
    "    corrupted_residual_component[:, pos, :] = clean_cache[hook.name][:, pos, :]\n",
    "    return corrupted_residual_component\n",
    "\n",
    "def normalize_patched_logit_diff(patched_logit_diff, original_logit_diff, corrupted_logit_diff):\n",
    "    \"\"\"Normalize the patched logit difference to measure improvement.\"\"\"\n",
    "    # 0 means no change, 1 means fully recovered performance\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (original_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "def run_residual_stream_patching(faithful_example, unfaithful_example, model):\n",
    "    \"\"\"Run residual stream patching between faithful and unfaithful examples.\"\"\"\n",
    "    # Tokenize both examples\n",
    "    faithful_tokens = model.to_tokens(faithful_example['generated_cot'], prepend_bos=True)\n",
    "    unfaithful_tokens = model.to_tokens(unfaithful_example['generated_cot'], prepend_bos=True)\n",
    "    print(f\"faithful_tokens.shape: {faithful_tokens.shape}, unfaithful_tokens.shape: {unfaithful_tokens.shape}\")\n",
    "    \n",
    "    # Get the ground truth answer tokens\n",
    "    answer_token = model.to_single_token(faithful_example['ground_truth_answer'])\n",
    "    print(f\"answer_token: {answer_token}\")\n",
    "    \n",
    "    # Run the model on both examples and cache activations\n",
    "    faithful_logits, faithful_cache = model.run_with_cache(faithful_tokens)\n",
    "    unfaithful_logits, unfaithful_cache = model.run_with_cache(unfaithful_tokens)\n",
    "    print(f\"faithful_logits.shape: {faithful_logits.shape}, unfaithful_logits.shape: {unfaithful_logits.shape}\")\n",
    "    \n",
    "    # Get the original logit values for the correct answer\n",
    "    faithful_answer_logit = faithful_logits[0, -1, answer_token].item()\n",
    "    unfaithful_answer_logit = unfaithful_logits[0, -1, answer_token].item()\n",
    "    \n",
    "    # Initialize results matrix\n",
    "    patched_results = torch.zeros(model.cfg.n_layers, min(faithful_tokens.shape[1], unfaithful_tokens.shape[1]))\n",
    "    \n",
    "    # For each layer and position, patch the unfaithful run with the faithful activation\n",
    "    for layer in tqdm(range(model.cfg.n_layers), desc=\"Patching layers\"):\n",
    "        for position in tqdm(range(min(faithful_tokens.shape[1], unfaithful_tokens.shape[1])), desc=\"Patching positions\"):\n",
    "            hook_fn = partial(patch_residual_component, pos=position, clean_cache=faithful_cache)\n",
    "            \n",
    "            patched_logits = model.run_with_hooks(\n",
    "                unfaithful_tokens,\n",
    "                fwd_hooks=[(f\"blocks.{layer}.hook_resid_pre\", hook_fn)],\n",
    "                return_type=\"logits\"\n",
    "            )\n",
    "            \n",
    "            patched_answer_logit = patched_logits[0, -1, answer_token].item()\n",
    "            \n",
    "            # Normalize the improvement\n",
    "            patched_results[layer, position] = normalize_patched_logit_diff(\n",
    "                patched_answer_logit, \n",
    "                faithful_answer_logit, \n",
    "                unfaithful_answer_logit\n",
    "            )\n",
    "    \n",
    "    return patched_results, faithful_tokens, unfaithful_tokens\n",
    "\n",
    "# Run the analysis on a pair of examples\n",
    "faithful_example = cots_faithful[0]\n",
    "unfaithful_example = cots_unfaithful[0]\n",
    "\n",
    "patched_results, faithful_tokens, unfaithful_tokens = run_residual_stream_patching(\n",
    "    faithful_example, \n",
    "    unfaithful_example, \n",
    "    model\n",
    ")\n",
    "\n",
    "# Visualize the results\n",
    "faithful_str_tokens = model.to_str_tokens(faithful_tokens[0])\n",
    "position_labels = [f\"{tok}_{i}\" for i, tok in enumerate(faithful_str_tokens)]\n",
    "\n",
    "fig = px.imshow(\n",
    "    patched_results.cpu().numpy(),\n",
    "    x=position_labels[:patched_results.shape[1]],\n",
    "    labels={\"x\": \"Position\", \"y\": \"Layer\"},\n",
    "    title=\"Impact of Patching Residual Stream from Faithful to Unfaithful CoT\",\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    color_continuous_midpoint=0.0\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
